---
layout: post
title: '유용한 링크 및 기초 지식'
category: Project-plan
tag: Capstone
---

정규화
토큰화
textToSequence

전처리
타코트론 모델 구현
하이퍼 파라메터 설정
hparams
datautils


# Audio 전처리 및 신호 관련 기초 지식
<https://hyunlee103.tistory.com/47>

# 푸리에 변환과 신호의 관계
<https://angeloyeo.github.io/2020/11/08/linear_algebra_and_Fourier_transform.html>

# 푸리에 변환과 푸리에 급수
<https://kkhipp.tistory.com/3>

# STFT
<https://jbear.tistory.com/entry/STFT-Short-Time-Furier-Transform-%EC%9D%98-%EA%B8%B0%EB%B3%B8%EA%B0%9C%EB%85%90-2>

# 타코트론

## 타코트론 논문 정리
1. 타코트론 1: <https://chldkato.tistory.com/143>
2. 타코트론 2: <https://joungheekim.github.io/2020/10/08/paper-review/>

## 타코트론 2

1. Nvidia: <https://github.com/NVIDIA/tacotron2>
2. 한국어 TTS: <https://github.com/hccho2/Tacotron2-Wavenet-Korean-TTS>

## 한국어 VAE 타코트론
<https://github.com/jinhan/tacotron2-vae>

## 타코트론 코드리뷰 및 개인화 TTS 방법
<https://joungheekim.github.io/2021/04/02/code-review/>

## Hifi-gan
<https://github.com/jik876/hifi-gan>

# Alignment map(Attention map)
1. how to read aligment graph?: <https://github.com/keithito/tacotron/issues/144>


## VAE?
1. <https://wikidocs.net/152474>
2. VAE 구현 코드 및 설명: <https://taeu.github.io/paper/deeplearning-paper-vae/>


# VAE 타코트론 분석

이분 깃 프로젝트를 보고 분석한 내용
<https://github.com/jinhan/tacotron2-vae>

## Training files format

nvidia도 그렇고 이분도 그렇고 데이터 셋(Text와 wav 파일) 형식을 다음과 같이 로드한다.
```
/KoreanEmotionSpeech/wav/neu/neu_00002289.wav|선생님이 초록색으로 머리를 염색하고 나타나서 모두들 깜짝 놀랐다.|0|0
/KoreanEmotionSpeech/wav/sad/sad_00002266.wav|과외 선생님이 열심히 지도해준 덕택에 수학실력이 점점 늘고 있다.|0|1
/KoreanEmotionSpeech/wav/ang/ang_00000019.wav|명백한 것은 각 당이 투사하고 있는 실상과 허상이 있다면 이제 허상은 걷어들여야 한다는 것이다.|0|2
/KoreanEmotionSpeech/wav/hap/hap_00001920.wav|강력한 스크럽으로 상쾌한 양치효과를 주네요.|0|3
```

현재 가지고 있는 데이터 셋은 이러한 형식이 아니고 json인데, json을 파싱하려면 각 속성이 어떤 역할을 하는지 파악할 필요가 있다고 생각한다.

wav 파일 경로|텍스트|스피커|감정|

wav 파일 경로: 학습 또는 정답 음성 파일
텍스트: 학습 wav 또는 정답 wav에 매칭되는 텍스트
스피커: ?
감정: 감정 데이터


![](/asset/images/20230310213252.png)
위 함수는 file이 들어오면 wav 파일 경로|텍스트|스피커|감정| 형식을 wav , 텍스트 , 스피커, 감정 형태로 분리하는 작업을 수행한다.



